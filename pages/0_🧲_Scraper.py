import streamlit as st

st.set_page_config(
    page_title="Scraping Guide",
    page_icon="ğŸ§²",
    layout="wide"
)

st.title("ğŸ§² Google Play ë¦¬ë·° Scraper (Colab Style)")

st.markdown(
    """
ì›í•˜ëŠ” **App ID**, **ë¦¬ë·° ê°œìˆ˜**, **ì–¸ì–´/ìŠ¤í† ì–´**ë¥¼ ì„ íƒí•˜ë©´  
Google Colabì—ì„œ ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ **ìŠ¤í¬ë˜í•‘ + ì •ì œ + CSV ë‹¤ìš´ë¡œë“œ** ì½”ë“œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.

> âš  ì´ í˜ì´ì§€ì—ì„œëŠ” ì‹¤ì œ ìŠ¤í¬ë˜í•‘ì„ í•˜ì§€ ì•Šê³ , **ì½”ë“œë§Œ ë§Œë“¤ì–´ì„œ ë³´ì—¬ì£¼ëŠ” ìš©ë„**ì…ë‹ˆë‹¤.
"""
)
st.markdown("---")

# --------------------------------------------------------
# 0) ì–¸ì–´ / ìŠ¤í† ì–´ ë§¤í•‘
# --------------------------------------------------------
LANG_MAP = {
    "í•œêµ­ì–´ ğŸ‡°ğŸ‡· (í•œêµ­ ìŠ¤í† ì–´)": {
        "lang": "ko",
        "country": "kr",
        "is_korean": True,
        "desc": "í•œêµ­ì–´ ë¦¬ë·° + í•œêµ­ ìŠ¤í† ì–´ ê¸°ì¤€"
    },
    "ì˜ì–´ ğŸ‡ºğŸ‡¸ (ë¯¸êµ­ ìŠ¤í† ì–´)": {
        "lang": "en",
        "country": "us",
        "is_korean": False,
        "desc": "ì˜ì–´ ë¦¬ë·° + ë¯¸êµ­ ìŠ¤í† ì–´ ê¸°ì¤€"
    },
    "ì¼ë³¸ì–´ ğŸ‡¯ğŸ‡µ (ì¼ë³¸ ìŠ¤í† ì–´)": {
        "lang": "ja",
        "country": "jp",
        "is_korean": False,
        "desc": "ì¼ë³¸ì–´ ë¦¬ë·° + ì¼ë³¸ ìŠ¤í† ì–´ ê¸°ì¤€"
    },
    "ì¤‘êµ­ì–´ ë²ˆì²´ ğŸ‡¹ğŸ‡¼ (ëŒ€ë§Œ ìŠ¤í† ì–´)": {
        "lang": "zh",
        "country": "tw",
        "is_korean": False,
        "desc": "ì¤‘êµ­ì–´(ë²ˆì²´) ë¦¬ë·° + ëŒ€ë§Œ ìŠ¤í† ì–´ ê¸°ì¤€"
    },
    "ë…ì¼ì–´ ğŸ‡©ğŸ‡ª (ë…ì¼ ìŠ¤í† ì–´)": {
        "lang": "de",
        "country": "de",
        "is_korean": False,
        "desc": "ë…ì¼ì–´ ë¦¬ë·° + ë…ì¼ ìŠ¤í† ì–´ ê¸°ì¤€"
    },
}

# --------------------------------------------------------
# 1) ì‚¬ìš©ì ì…ë ¥ (App ID + ë¦¬ë·° ìˆ˜ + ì–¸ì–´ ì„ íƒ)
# --------------------------------------------------------
st.header("1ï¸âƒ£ ìŠ¤í¬ë˜í•‘ ì˜µì…˜ ì„¤ì •")

col1, col2, col3 = st.columns([2.2, 1.3, 1.5])

with col1:
    app_id = st.text_input(
        "App ID ì…ë ¥",
        placeholder="ì˜ˆ: com.nexon.devcat.mabinogi_m",
        help="Google Play URLì˜ id= ë’¤ì— ë‚˜ì˜¤ëŠ” ë¬¸ìì—´ì´ App ID ì…ë‹ˆë‹¤."
    )

with col2:
    review_count = st.number_input(
        "ë¦¬ë·° ìˆ˜ (max_reviews)",
        min_value=100,
        max_value=50000,
        value=30000,
        step=500,
        help="ìŠ¤í¬ë©í•  ë¦¬ë·° ìµœëŒ€ ê°œìˆ˜"
    )

with col3:
    lang_label = st.selectbox(
        "ì–¸ì–´ / ìŠ¤í† ì–´ ì„ íƒ",
        options=list(LANG_MAP.keys()),
        index=0
    )

lang_info = LANG_MAP[lang_label]
lang_code = lang_info["lang"]
country_code = lang_info["country"]
is_korean = lang_info["is_korean"]

st.caption(f"ğŸŒ ì„ íƒí•œ ì˜µì…˜: `{lang_code}-{country_code}` Â· {lang_info['desc']}")
st.caption("ğŸ’¡ App IDë§Œ ë°”ê¾¸ë©´ ì›í•˜ëŠ” ì•±ì˜ ë¦¬ë·°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
st.markdown("---")

# --------------------------------------------------------
# 2) ì–¸ì–´ë³„ ì •ì œ ì½”ë“œ ë¸”ëŸ­ ìƒì„±
# --------------------------------------------------------
if is_korean:
    # í•œêµ­ì–´ ì „ìš©: í•œê¸€ ë¹„ìœ¨ í•„í„° + ë…¸ì´ì¦ˆ ì œê±° + content_clean
    cleaning_block = """
# ===============================
# 4. í•œêµ­ì–´ ë¹„ìœ¨ ê¸°ë°˜ í•„í„°ë§ + ë…¸ì´ì¦ˆ ì œê±°
# ===============================

# 4-1) ê²°ì¸¡/ì¤‘ë³µ ì •ë¦¬
df["content"] = df["content"].fillna("").astype(str).str.strip()
df = df.drop_duplicates(subset=["reviewId"])

# 4-2) í•œê¸€ ë¹„ìœ¨ ê³„ì‚° í•¨ìˆ˜
_hangul = re.compile(r"[\\uac00-\\ud7a3]")   # ê°€-í£

def korean_ratio(text: str) -> float:
    if not text:
        return 0.0
    hangul_cnt = len(_hangul.findall(text))
    return hangul_cnt / max(len(text), 1)

# 4-3) í•œêµ­ì–´ ë¦¬ë·°ë§Œ í•„í„° (ë¹„ìœ¨ ì„ê³„ê°’ 0.6)
THRESH = 0.6
df["ko_ratio"] = df["content"].apply(korean_ratio)
ko_df = df[df["ko_ratio"] >= THRESH].copy()

# 4-4) ë…¸ì´ì¦ˆ ì œê±°: URL/ì´ëª¨ì§€/ì—¬ë°±
url_pat = r"https?://\\S+|www\\.\\S+"
emoji_pat = r"[\\U00010000-\\U0010ffff]"  # ëŒ€ë¶€ë¶„ ì´ëª¨ì§€ ë²”ìœ„

ko_df["content_clean"] = (
    ko_df["content"]
      .str.replace(url_pat, " ", regex=True)
      .str.replace(emoji_pat, " ", regex=True)
      .str.replace(r"\\s+", " ", regex=True)
      .str.strip()
)

print("ì›ë³¸ ë¦¬ë·° ê°œìˆ˜:", len(df))
print("í•œêµ­ì–´ í•„í„°ë§ í›„ ê°œìˆ˜:", len(ko_df))
ko_df[["userName","score","content_clean"]].head()

clean_df = ko_df  # ì´í›„ ê³µí†µ ì²˜ë¦¬ìš©
"""
    output_name = "reviews_clean_ko.csv"
else:
    # ê¸°íƒ€ ì–¸ì–´: ê¸°ë³¸ ì •ì œ + content_clean
    cleaning_block = """
# ===============================
# 4. ê¸°ë³¸ í…ìŠ¤íŠ¸ ì •ì œ (ê³µí†µ)
# ===============================

# 4-1) ê²°ì¸¡/ì¤‘ë³µ ì •ë¦¬
df["content"] = df["content"].fillna("").astype(str).str.strip()
df = df.drop_duplicates(subset=["reviewId"])

# 4-2) ë…¸ì´ì¦ˆ ì œê±°: URL/ì´ëª¨ì§€/ì—¬ë°±
url_pat = r"https?://\\S+|www\\.\\S+"
emoji_pat = r"[\\U00010000-\\U0010ffff]"  # ëŒ€ë¶€ë¶„ ì´ëª¨ì§€ ë²”ìœ„

df["content_clean"] = (
    df["content"]
      .str.replace(url_pat, " ", regex=True)
      .str.replace(emoji_pat, " ", regex=True)
      .str.replace(r"\\s+", " ", regex=True)
      .str.strip()
)

print("ì •ì œ í›„ ë¦¬ë·° ê°œìˆ˜:", len(df))
df[["userName","score","content_clean"]].head()

clean_df = df  # ì´í›„ ê³µí†µ ì²˜ë¦¬ìš©
"""
    output_name = f"reviews_clean_{lang_code}.csv"

# --------------------------------------------------------
# 3) Colab ì½”ë“œ ì „ì²´ ìƒì„±
# --------------------------------------------------------
st.header("2ï¸âƒ£ Colabì—ì„œ ì‹¤í–‰í•  ì½”ë“œ ë¯¸ë¦¬ë³´ê¸°")

if not app_id.strip():
    st.info("ğŸ‘† **ë¨¼ì € App IDë¥¼ ì…ë ¥í•˜ë©´ ì•„ë˜ì— Colab ì½”ë“œê°€ ìƒì„±ë©ë‹ˆë‹¤.**")
else:
    code_block = f"""
# ===============================
# 0. Google Play Scraper ì„¤ì¹˜
# ===============================
!pip install google-play-scraper

# ===============================
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ
# ===============================
from google_play_scraper import reviews, Sort
import pandas as pd
import re

# ===============================
# 2. ìŠ¤í¬ë˜í•‘ ê¸°ë³¸ ì„¤ì •
# ===============================
app_id = "{app_id}"          # ìŠ¤í¬ë©í•  ì•± ID
max_reviews = {review_count} # ìµœëŒ€ ë¦¬ë·° ê°œìˆ˜

lang = "{lang_code}"         # ì–¸ì–´ ì½”ë“œ
country = "{country_code}"   # ìŠ¤í† ì–´ êµ­ê°€ ì½”ë“œ

# ===============================
# 3. ë¦¬ë·° ìŠ¤í¬ë˜í•‘ ì‹¤í–‰
# ===============================
result, continuation_token = reviews(
    app_id,
    lang=lang,
    country=country,
    count=max_reviews,
    sort=Sort.NEWEST
)

df = pd.DataFrame(result)

print("ìŠ¤í¬ë˜í•‘ ì™„ë£Œ! ì›ë³¸ ë¦¬ë·° ê°œìˆ˜:", len(df))
df.head()
{cleaning_block}

# ===============================
# 5. ì •ì œëœ ë¦¬ë·° CSV ì €ì¥ & ë‹¤ìš´ë¡œë“œ
# ===============================
output_path = "{output_name}"
clean_df.to_csv(output_path, index=False, encoding="utf-8-sig")

print("ì •ì œëœ ë¦¬ë·° CSV ì €ì¥ ì™„ë£Œ â†’", output_path)

from google.colab import files
files.download(output_path)
"""

    st.code(code_block, language="python")
    st.success("âœ… ìœ„ ì½”ë“œ ë¸”ë¡ì„ Colabì— ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ìœ¼ë©´ ìŠ¤í¬ë˜í•‘ â†’ ì •ì œ â†’ CSV ë‹¤ìš´ë¡œë“œê¹Œì§€ í•œ ë²ˆì— ì‹¤í–‰ë©ë‹ˆë‹¤.")

    st.markdown("---")
    st.header("3ï¸âƒ£ ì‚¬ìš© ë°©ë²• ìš”ì•½")
    st.markdown(
        """
1. **Google Colab** ìƒˆ ë…¸íŠ¸ë¥¼ ì—°ë‹¤.  
2. ìœ„ ì½”ë“œ ì „ì²´ë¥¼ **í•˜ë‚˜ì˜ ì…€ì— ë¶™ì—¬ë„£ê³  ì‹¤í–‰**í•œë‹¤.  
3. ì‹¤í–‰ì´ ëë‚˜ë©´  
   - `reviews_clean_*.csv` íŒŒì¼ì´ ìƒì„±ë˜ê³   
   - ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ íŒì—…ì´ ëœ¬ë‹¤.  
4. ë‹¤ìš´ë¡œë“œí•œ CSV íŒŒì¼ì„ ì´ Streamlit ì•±ì˜ **Session Setup(maincopy.py)** í˜ì´ì§€ì—ì„œ ì—…ë¡œë“œí•˜ë©´  
   â†’ ì „ì²˜ë¦¬ Â· í´ëŸ¬ìŠ¤í„°ë§ Â· LLM ë¶„ì„ê¹Œì§€ ë°”ë¡œ ì´ì–´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
"""
    )

st.info("â— Streamlit ìª½ì—ì„œëŠ” ì‹¤ì œ ìŠ¤í¬ë˜í•‘ì„ í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—, ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì—†ì´ ì•ˆì „í•˜ê²Œ ëŒì•„ê°‘ë‹ˆë‹¤.")
